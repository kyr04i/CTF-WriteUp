diff --git a/src/builtins/promise-all-element-closure.tq b/src/builtins/promise-all-element-closure.tq
index 276e69fde49..10ade44a176 100644
--- a/src/builtins/promise-all-element-closure.tq
+++ b/src/builtins/promise-all-element-closure.tq
@@ -175,22 +175,11 @@ transitioning macro PromiseAllResolveElementClosure<F: type>(
         *NativeContextSlot(
         nativeContext, ContextSlot::JS_ARRAY_PACKED_ELEMENTS_MAP_INDEX);
 
-    // After this point, values escapes to user code.
-    //
-    // If resolve and reject handlers close over values to keep track of
-    // whether an input promise is already settled, mark the values array as
-    // COW. The original values array is still needed to guard against resolve
-    // or reject being called multiple times for an element.
-    //
-    // Otherwise, clear the slot.
-    if (hasResolveAndRejectClosures) {
-      MakeFixedArrayCOW(values);
-    } else {
-      *ContextSlot(
-          promiseContext,
-          PromiseAllResolveElementContextSlots::
-              kPromiseAllResolveElementValuesSlot) = kEmptyFixedArray;
-    }
+    // If resolve and reject handlers close over values to keep track of whether
+    // an input promise is already settled, mark the values array as COW before
+    // letting it escape to user code.
+    if (hasResolveAndRejectClosures) MakeFixedArrayCOW(values);
+
     const valuesArray = NewJSArray(arrayMap, values);
     Call(promiseContext, resolve, Undefined, valuesArray);
   }
diff --git a/src/builtins/promise-all.tq b/src/builtins/promise-all.tq
index 24c4ab7145c..34b60ea53db 100644
--- a/src/builtins/promise-all.tq
+++ b/src/builtins/promise-all.tq
@@ -283,16 +283,15 @@ Reject(JSAny) {
 
   check(remainingElementsCount >= 0);
 
-  const valuesRef:&FixedArray = ContextSlot(
-      resolveElementContext,
-      PromiseAllResolveElementContextSlots::
-          kPromiseAllResolveElementValuesSlot);
-  const values = *valuesRef;
-
   if (remainingElementsCount > 0) {
     // Pre-allocate the backing store for the {values} to the desired
     // capacity. We may already have elements in "values" - this happens
     // when the Thenable calls the resolve callback immediately.
+    const valuesRef:&FixedArray = ContextSlot(
+        resolveElementContext,
+        PromiseAllResolveElementContextSlots::
+            kPromiseAllResolveElementValuesSlot);
+    const values = *valuesRef;
     // 'index' is a 1-based index and incremented after every Promise. Later we
     // use 'values' as a 0-based array, so capacity 'index - 1' is enough.
     const newCapacity = SmiUntag(index) - 1;
@@ -307,23 +306,19 @@ Reject(JSAny) {
       //     Let valuesArray be CreateArrayFromList(values).
       //     Perform ? Call(resultCapability.[[Resolve]], undefined,
       //                    « valuesArray »).
+
+      const values: FixedArray = *ContextSlot(
+          resolveElementContext,
+          PromiseAllResolveElementContextSlots::
+              kPromiseAllResolveElementValuesSlot);
       const arrayMap =
           *NativeContextSlot(
           nativeContext, ContextSlot::JS_ARRAY_PACKED_ELEMENTS_MAP_INDEX);
 
-      // After this point, values escapes to user code.
-      //
       // If resolve and reject handlers close over values to keep track of
       // whether an input promise is already settled, mark the values array as
-      // COW. The original values array is still needed to guard against resolve
-      // or reject being called multiple times for an element.
-      //
-      // Otherwise, clear the slot.
-      if (hasResolveAndRejectClosures) {
-        MakeFixedArrayCOW(values);
-      } else {
-        *valuesRef = kEmptyFixedArray;
-      }
+      // COW before letting it escape to user code.
+      if (hasResolveAndRejectClosures) MakeFixedArrayCOW(values);
 
       const valuesArray = NewJSArray(arrayMap, values);
       Call(nativeContext, UnsafeCast<JSAny>(resolve), Undefined, valuesArray);
diff --git a/src/builtins/promise-any.tq b/src/builtins/promise-any.tq
index 8b21ebfff0f..2c4b4f0cdcb 100644
--- a/src/builtins/promise-any.tq
+++ b/src/builtins/promise-any.tq
@@ -315,14 +315,10 @@ Reject(JSAny) {
 
       // We may already have elements in "errors" - this happens when the
       // Thenable calls the reject callback immediately.
-      const errorsRef:&FixedArray = ContextSlot(
+      const errors: FixedArray = *ContextSlot(
           rejectElementContext,
           PromiseAnyRejectElementContextSlots::
               kPromiseAnyRejectElementErrorsSlot);
-      const errors: FixedArray = *errorsRef;
-
-      // After this point, errors escapes to user code. Clear the slot.
-      *errorsRef = kEmptyFixedArray;
 
       check(errors.length == index - 1);
       const error = ConstructAggregateError(errors);
diff --git a/src/d8/d8.cc b/src/d8/d8.cc
index b621e7e51ad..f379d8f3c85 100644
--- a/src/d8/d8.cc
+++ b/src/d8/d8.cc
@@ -2007,9 +2007,9 @@ MaybeLocal<Context> Shell::CreateRealm(
     }
     delete[] old_realms;
   }
-  Local<ObjectTemplate> global_template = CreateGlobalTemplate(isolate);
+  // Local<ObjectTemplate> global_template = CreateGlobalTemplate(isolate);
   Local<Context> context =
-      Context::New(isolate, nullptr, global_template, global_object);
+      Context::New(isolate, nullptr, ObjectTemplate::New(isolate), global_object);
   if (context.IsEmpty()) return MaybeLocal<Context>();
   DCHECK(!try_catch.HasCaught());
   InitializeModuleEmbedderData(context);
@@ -3735,9 +3735,9 @@ MaybeLocal<Context> Shell::CreateEvaluationContext(Isolate* isolate) {
       reinterpret_cast<i::Isolate*>(isolate)->main_thread_local_isolate(),
       context_mutex_.Pointer());
   // Initialize the global objects
-  Local<ObjectTemplate> global_template = CreateGlobalTemplate(isolate);
+  // Local<ObjectTemplate> global_template = CreateGlobalTemplate(isolate);
   EscapableHandleScope handle_scope(isolate);
-  Local<Context> context = Context::New(isolate, nullptr, global_template);
+  Local<Context> context = Context::New(isolate, nullptr, ObjectTemplate::New(isolate));
   if (context.IsEmpty()) {
     DCHECK(isolate->IsExecutionTerminating());
     return {};
diff --git a/src/heap/concurrent-marking.cc b/src/heap/concurrent-marking.cc
index ee46be78da3..0d99b5cadb1 100644
--- a/src/heap/concurrent-marking.cc
+++ b/src/heap/concurrent-marking.cc
@@ -338,8 +338,6 @@ void ConcurrentMarking::RunMajor(JobDelegate* delegate,
           local_marking_worklists.PushOnHold(object);
         } else {
           Tagged<Map> map = object->map(cage_base, kAcquireLoad);
-          // The marking worklist should never contain filler objects.
-          CHECK(!IsFreeSpaceOrFillerMap(map));
           if (is_per_context_mode) {
             Address context;
             if (native_context_inferrer.Infer(cage_base, map, object,
diff --git a/src/heap/mark-compact.cc b/src/heap/mark-compact.cc
index 372f6f74ff9..47017c6ccbb 100644
--- a/src/heap/mark-compact.cc
+++ b/src/heap/mark-compact.cc
@@ -2200,8 +2200,21 @@ std::pair<size_t, size_t> MarkCompactCollector::ProcessMarkingWorklist(
 
   while (local_marking_worklists_->Pop(&object) ||
          local_marking_worklists_->PopOnHold(&object)) {
-    // The marking worklist should never contain filler objects.
-    CHECK(!IsFreeSpaceOrFiller(object, cage_base));
+    // Left trimming may result in grey or black filler objects on the marking
+    // worklist. Ignore these objects.
+    if (IsFreeSpaceOrFiller(object, cage_base)) {
+      // Due to copying mark bits and the fact that grey and black have their
+      // first bit set, one word fillers are always black.
+      DCHECK_IMPLIES(object->map(cage_base) ==
+                         ReadOnlyRoots(isolate).one_pointer_filler_map(),
+                     marking_state_->IsMarked(object));
+      // Other fillers may be black or grey depending on the color of the object
+      // that was trimmed.
+      DCHECK_IMPLIES(object->map(cage_base) !=
+                         ReadOnlyRoots(isolate).one_pointer_filler_map(),
+                     marking_state_->IsMarked(object));
+      continue;
+    }
     DCHECK(IsHeapObject(object));
     DCHECK(!object.InReadOnlySpace());
     DCHECK_EQ(GetIsolateFromWritableObject(object), isolate);
diff --git a/src/heap/marking-visitor-inl.h b/src/heap/marking-visitor-inl.h
index 15cabba0368..c56fe3da0ab 100644
--- a/src/heap/marking-visitor-inl.h
+++ b/src/heap/marking-visitor-inl.h
@@ -57,17 +57,17 @@ void MarkingVisitorBase<ConcreteVisitor>::ProcessStrongHeapObject(
   SynchronizePageAccess(heap_object);
   if (!ShouldMarkObject(heap_object)) return;
   // TODO(chromium:1495151): Remove after diagnosing.
-  if (V8_UNLIKELY(!BasicMemoryChunk::FromHeapObject(heap_object)->IsMarking() &&
-                  IsFreeSpaceOrFiller(
-                      heap_object, ObjectVisitorWithCageBases::cage_base()))) {
-    heap_->isolate()->PushStackTraceAndDie(
-        reinterpret_cast<void*>(host->map().ptr()),
-        reinterpret_cast<void*>(host->address()),
-        reinterpret_cast<void*>(slot.address()),
-        reinterpret_cast<void*>(BasicMemoryChunk::FromHeapObject(heap_object)
-                                    ->owner()
-                                    ->identity()));
-  }
+  // if (V8_UNLIKELY(!BasicMemoryChunk::FromHeapObject(heap_object)->IsMarking() &&
+  //                 IsFreeSpaceOrFiller(
+  //                     heap_object, ObjectVisitorWithCageBases::cage_base()))) {
+  //   heap_->isolate()->PushStackTraceAndDie(
+  //       reinterpret_cast<void*>(host->map().ptr()),
+  //       reinterpret_cast<void*>(host->address()),
+  //       reinterpret_cast<void*>(slot.address()),
+  //       reinterpret_cast<void*>(BasicMemoryChunk::FromHeapObject(heap_object)
+  //                                   ->owner()
+  //                                   ->identity()));
+  // }
   MarkObject(host, heap_object);
   concrete_visitor()->RecordSlot(host, slot, heap_object);
 }
